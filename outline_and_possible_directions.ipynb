{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPT Version of the Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If youâ€™re using the **TMDb API** to build a **movie recommender system** with **Apache Airflow**, hereâ€™s a structured **end-to-end approach**:\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 1: Define the Architecture**\n",
    "Your workflow involves:\n",
    "1. **Data Ingestion** â€“ Extract movie data from TMDb API.\n",
    "2. **Data Storage** â€“ Store movie metadata in a distributed database (e.g., Snowflake, BigQuery, or PostgreSQL).\n",
    "3. **Feature Engineering** â€“ Transform and preprocess the data.\n",
    "4. **Model Training** â€“ Build a recommender system using collaborative filtering, content-based filtering, or hybrid models.\n",
    "5. **Model Deployment & API** â€“ Deploy a model that serves recommendations via an API.\n",
    "\n",
    "### **Tech Stack**\n",
    "- **Apache Airflow** (Orchestrator)\n",
    "- **TMDb API** (Data Source)\n",
    "- **Snowflake/BigQuery/PostgreSQL** (Storage)\n",
    "- **Spark/Pandas** (Processing)\n",
    "- **Scikit-learn/Surprise/LightFM** (Modeling)\n",
    "- **Flask/FastAPI** (API for serving recommendations)\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 2: Set Up Apache Airflow DAG for Data Ingestion**\n",
    "The first DAG will:\n",
    "- Query TMDb API daily for new/updated movies.\n",
    "- Store the data in a database.\n",
    "\n",
    "### **Tasks for Airflow DAG**\n",
    "1. **Extract Data from TMDb API**\n",
    "   - Use `requests` to fetch movie metadata.\n",
    "   - Query popular, trending, and newly released movies.\n",
    "2. **Transform Data**\n",
    "   - Normalize JSON response.\n",
    "   - Extract relevant fields (movie ID, title, genre, cast, etc.).\n",
    "3. **Load Data into a Database**\n",
    "   - Store the movie data in **Snowflake, PostgreSQL, or BigQuery**.\n",
    "\n",
    "### **Airflow DAG Code (ETL Pipeline)**\n",
    "```python\n",
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "\n",
    "# TMDb API Config\n",
    "API_KEY = \"your_tmdb_api_key\"\n",
    "BASE_URL = \"https://api.themoviedb.org/3\"\n",
    "\n",
    "# Database Connection (PostgreSQL Example)\n",
    "DATABASE_URI = \"postgresql+psycopg2://user:password@host:5432/moviedb\"\n",
    "engine = sqlalchemy.create_engine(DATABASE_URI)\n",
    "\n",
    "def fetch_movies():\n",
    "    \"\"\"Fetch movie data from TMDb API.\"\"\"\n",
    "    url = f\"{BASE_URL}/movie/popular?api_key={API_KEY}&language=en-US&page=1\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()[\"results\"]\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"id\", \"title\", \"release_date\", \"vote_average\", \"genre_ids\", \"overview\"])\n",
    "    df.to_sql(\"movies\", con=engine, if_exists=\"append\", index=False)\n",
    "\n",
    "default_args = {\n",
    "    \"owner\": \"airflow\",\n",
    "    \"depends_on_past\": False,\n",
    "    \"start_date\": datetime(2024, 2, 1),\n",
    "    \"retries\": 1,\n",
    "    \"retry_delay\": timedelta(minutes=5),\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    \"tmdb_movie_etl\",\n",
    "    default_args=default_args,\n",
    "    schedule_interval=\"@daily\",\n",
    "    catchup=False,\n",
    ")\n",
    "\n",
    "fetch_movies_task = PythonOperator(\n",
    "    task_id=\"fetch_movies\",\n",
    "    python_callable=fetch_movies,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "fetch_movies_task\n",
    "```\n",
    "---\n",
    "## **Step 3: Feature Engineering**\n",
    "- Process the stored movie data.\n",
    "- Convert genres and keywords into **one-hot encoded vectors**.\n",
    "- Extract text-based features from movie descriptions (`TF-IDF`).\n",
    "- Normalize ratings for similarity computation.\n",
    "\n",
    "Example: **Processing Genres for Content-Based Filtering**\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "df = pd.read_sql(\"SELECT id, title, genre_ids FROM movies\", con=engine)\n",
    "\n",
    "# Convert genre_ids to list\n",
    "df[\"genre_ids\"] = df[\"genre_ids\"].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# One-hot encode genres\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_encoded = pd.DataFrame(mlb.fit_transform(df[\"genre_ids\"]), columns=mlb.classes_)\n",
    "df = df.drop(columns=[\"genre_ids\"]).join(genres_encoded)\n",
    "\n",
    "df.to_sql(\"movies_processed\", con=engine, if_exists=\"replace\", index=False)\n",
    "```\n",
    "---\n",
    "## **Step 4: Build the Recommender System**\n",
    "You can use **two main approaches**:\n",
    "### **1. Content-Based Filtering (Using Cosine Similarity)**\n",
    "- Compute similarity based on **genres, keywords, descriptions**.\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load preprocessed data\n",
    "df = pd.read_sql(\"SELECT * FROM movies_processed\", con=engine)\n",
    "\n",
    "# Convert overview text into TF-IDF features\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf_matrix = tfidf.fit_transform(df[\"overview\"].fillna(\"\"))\n",
    "\n",
    "# Compute similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Store similarity matrix\n",
    "import numpy as np\n",
    "np.save(\"movie_similarity.npy\", cosine_sim)\n",
    "```\n",
    "\n",
    "### **2. Collaborative Filtering (Using Surprise)**\n",
    "- Uses user ratings to recommend movies.\n",
    "\n",
    "```python\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load user ratings\n",
    "df_ratings = pd.read_sql(\"SELECT user_id, movie_id, rating FROM ratings\", con=engine)\n",
    "\n",
    "# Prepare dataset\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_ratings[[\"user_id\", \"movie_id\", \"rating\"]], reader)\n",
    "\n",
    "# Train model\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Save model\n",
    "import pickle\n",
    "with open(\"collab_filtering_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "```\n",
    "---\n",
    "## **Step 5: Deploy the Recommender System**\n",
    "Once trained, deploy a **Flask or FastAPI** service that serves recommendations.\n",
    "\n",
    "### **Flask API for Movie Recommendations**\n",
    "```python\n",
    "from flask import Flask, request, jsonify\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load similarity matrix\n",
    "cosine_sim = np.load(\"movie_similarity.npy\")\n",
    "\n",
    "@app.route(\"/recommend\", methods=[\"GET\"])\n",
    "def recommend():\n",
    "    movie_id = int(request.args.get(\"movie_id\"))\n",
    "    idx = df[df[\"id\"] == movie_id].index[0]\n",
    "    \n",
    "    # Get top similar movies\n",
    "    similar_indices = cosine_sim[idx].argsort()[-6:-1][::-1]\n",
    "    recommendations = df.iloc[similar_indices][[\"id\", \"title\"]].to_dict(orient=\"records\")\n",
    "\n",
    "    return jsonify(recommendations)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n",
    "```\n",
    "---\n",
    "## **Step 6: Automate Everything with Airflow**\n",
    "- **Ingestion DAG** â€“ Fetch new data daily.\n",
    "- **Processing DAG** â€“ Feature engineering weekly.\n",
    "- **Model Retraining DAG** â€“ Train recommender model monthly.\n",
    "- **API Deployment DAG** â€“ Deploy new model when retrained.\n",
    "\n",
    "---\n",
    "## **Final Thoughts**\n",
    "ðŸŽ¯ **By following this pipeline, you'll have:**\n",
    "- **Daily-updated** movie data from TMDb.\n",
    "- **A structured and scalable recommender system.**\n",
    "- **An Airflow-based automated pipeline.**\n",
    "- **A deployed API serving recommendations.**\n",
    "\n",
    "Would you like help setting up Airflow DAGs for **model training and deployment** as well? ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claude version of the response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll help you design a complete workflow for building a movie recommender system using TMDB API, Airflow, and MongoDB. Let me create an example implementation.\n",
    "\n",
    "\n",
    "\n",
    "I've created a complete Airflow DAG that implements a movie recommender system. Here's how the workflow functions:\n",
    "\n",
    "1. **Data Collection (Task 1)**:\n",
    "   - Fetches popular movies from TMDB API\n",
    "   - Stores raw data in MongoDB's `raw_movies` collection\n",
    "   - This creates our initial dataset\n",
    "\n",
    "2. **Data Enrichment (Task 2)**:\n",
    "   - Retrieves additional details for each movie (genres, runtime, budget)\n",
    "   - Fetches cast and crew information\n",
    "   - Stores enriched data in the `enriched_movies` collection\n",
    "\n",
    "3. **Feature Engineering (Task 3)**:\n",
    "   - Extracts relevant features from the enriched data\n",
    "   - Creates feature vectors including genres, cast, crew, and metrics\n",
    "   - Stores these in the `feature_vectors` collection\n",
    "\n",
    "4. **Recommendation Generation (Task 4)**:\n",
    "   - Builds a similarity matrix using cosine similarity\n",
    "   - Generates movie recommendations based on content features\n",
    "   - Stores recommendations in the `recommendations` collection\n",
    "\n",
    "MongoDB is integrated throughout the workflow in several meaningful ways:\n",
    "- Acts as a data lake for raw TMDB data\n",
    "- Stores enriched movie information\n",
    "- Maintains feature vectors for quick access\n",
    "- Persists final recommendations for serving\n",
    "\n",
    "To use this system:\n",
    "\n",
    "1. Set up your environment:\n",
    "```bash\n",
    "pip install apache-airflow pymongo pandas scikit-learn requests\n",
    "```\n",
    "\n",
    "2. Configure MongoDB and TMDB API:\n",
    "- Replace `'mongodb://localhost:27017/'` with your MongoDB connection string\n",
    "- Add your TMDB API key\n",
    "\n",
    "3. Deploy the DAG to your Airflow instance\n",
    "\n",
    "Would you like me to explain any specific part in more detail or add additional features to the system?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from pymongo import MongoClient\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# DAG default arguments\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime(2025, 2, 1),\n",
    "    'email_on_failure': False,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}\n",
    "\n",
    "# MongoDB connection setup\n",
    "def get_mongo_client():\n",
    "    return MongoClient('mongodb://localhost:27017/')\n",
    "\n",
    "# TMDB API configuration\n",
    "TMDB_API_KEY = 'your_api_key_here'\n",
    "TMDB_BASE_URL = 'https://api.themoviedb.org/3'\n",
    "\n",
    "# Task 1: Fetch movie data from TMDB\n",
    "def fetch_tmdb_data():\n",
    "    movies = []\n",
    "    for page in range(1, 11):  # Fetch first 10 pages\n",
    "        response = requests.get(\n",
    "            f'{TMDB_BASE_URL}/movie/popular',\n",
    "            params={\n",
    "                'api_key': TMDB_API_KEY,\n",
    "                'page': page\n",
    "            }\n",
    "        )\n",
    "        movies.extend(response.json()['results'])\n",
    "    \n",
    "    # Store in MongoDB\n",
    "    client = get_mongo_client()\n",
    "    db = client['movie_recommender']\n",
    "    collection = db['raw_movies']\n",
    "    collection.insert_many(movies)\n",
    "    client.close()\n",
    "\n",
    "# Task 2: Process and enrich movie data\n",
    "def process_movie_data():\n",
    "    client = get_mongo_client()\n",
    "    db = client['movie_recommender']\n",
    "    raw_movies = list(db['raw_movies'].find())\n",
    "    \n",
    "    # Enrich with additional movie details and credits\n",
    "    enriched_movies = []\n",
    "    for movie in raw_movies:\n",
    "        movie_id = movie['id']\n",
    "        # Fetch additional details\n",
    "        details = requests.get(\n",
    "            f'{TMDB_BASE_URL}/movie/{movie_id}',\n",
    "            params={'api_key': TMDB_API_KEY}\n",
    "        ).json()\n",
    "        \n",
    "        # Fetch credits\n",
    "        credits = requests.get(\n",
    "            f'{TMDB_BASE_URL}/movie/{movie_id}/credits',\n",
    "            params={'api_key': TMDB_API_KEY}\n",
    "        ).json()\n",
    "        \n",
    "        # Combine data\n",
    "        enriched_movie = {\n",
    "            **movie,\n",
    "            'genres': details.get('genres', []),\n",
    "            'runtime': details.get('runtime', 0),\n",
    "            'budget': details.get('budget', 0),\n",
    "            'revenue': details.get('revenue', 0),\n",
    "            'cast': credits.get('cast', [])[:5],  # Top 5 cast members\n",
    "            'crew': credits.get('crew', [])[:5]   # Top 5 crew members\n",
    "        }\n",
    "        enriched_movies.append(enriched_movie)\n",
    "    \n",
    "    # Store enriched data\n",
    "    db['enriched_movies'].insert_many(enriched_movies)\n",
    "    client.close()\n",
    "\n",
    "# Task 3: Build feature vectors\n",
    "def build_feature_vectors():\n",
    "    client = get_mongo_client()\n",
    "    db = client['movie_recommender']\n",
    "    movies = list(db['enriched_movies'].find())\n",
    "    \n",
    "    # Create feature vectors\n",
    "    feature_vectors = []\n",
    "    for movie in movies:\n",
    "        # Extract genres\n",
    "        genres = [genre['name'] for genre in movie['genres']]\n",
    "        \n",
    "        # Extract cast and crew\n",
    "        cast = [member['name'] for member in movie['cast']]\n",
    "        directors = [member['name'] for member in movie['crew'] \n",
    "                    if member['job'] == 'Director']\n",
    "        \n",
    "        # Create feature dictionary\n",
    "        features = {\n",
    "            'movie_id': movie['id'],\n",
    "            'title': movie['title'],\n",
    "            'genres': genres,\n",
    "            'cast': cast,\n",
    "            'directors': directors,\n",
    "            'popularity': movie['popularity'],\n",
    "            'vote_average': movie['vote_average'],\n",
    "            'vote_count': movie['vote_count']\n",
    "        }\n",
    "        feature_vectors.append(features)\n",
    "    \n",
    "    # Store feature vectors\n",
    "    db['feature_vectors'].insert_many(feature_vectors)\n",
    "    client.close()\n",
    "\n",
    "# Task 4: Generate recommendations\n",
    "def generate_recommendations():\n",
    "    client = get_mongo_client()\n",
    "    db = client['movie_recommender']\n",
    "    features = list(db['feature_vectors'].find())\n",
    "    \n",
    "    # Create similarity matrix\n",
    "    df = pd.DataFrame(features)\n",
    "    \n",
    "    # Create genre matrix (one-hot encoding)\n",
    "    genres = df['genres'].explode().unique()\n",
    "    genre_matrix = pd.DataFrame(\n",
    "        [[1 if genre in movie['genres'] else 0 for genre in genres] \n",
    "         for movie in features],\n",
    "        columns=genres\n",
    "    )\n",
    "    \n",
    "    # Normalize numerical features\n",
    "    numerical_features = df[['popularity', 'vote_average', 'vote_count']]\n",
    "    normalized_features = (numerical_features - numerical_features.mean()) / numerical_features.std()\n",
    "    \n",
    "    # Combine features\n",
    "    final_features = pd.concat([genre_matrix, normalized_features], axis=1)\n",
    "    \n",
    "    # Calculate similarity matrix\n",
    "    similarity_matrix = cosine_similarity(final_features)\n",
    "    \n",
    "    # Generate recommendations for each movie\n",
    "    recommendations = []\n",
    "    for i, movie in enumerate(features):\n",
    "        # Get top 5 similar movies\n",
    "        similar_indices = similarity_matrix[i].argsort()[-6:-1][::-1]\n",
    "        recommendation = {\n",
    "            'movie_id': movie['movie_id'],\n",
    "            'title': movie['title'],\n",
    "            'recommended_movies': [\n",
    "                {\n",
    "                    'movie_id': features[idx]['movie_id'],\n",
    "                    'title': features[idx]['title'],\n",
    "                    'similarity_score': float(similarity_matrix[i][idx])\n",
    "                }\n",
    "                for idx in similar_indices\n",
    "            ]\n",
    "        }\n",
    "        recommendations.append(recommendation)\n",
    "    \n",
    "    # Store recommendations\n",
    "    db['recommendations'].insert_many(recommendations)\n",
    "    client.close()\n",
    "\n",
    "# Create DAG\n",
    "dag = DAG(\n",
    "    'movie_recommender',\n",
    "    default_args=default_args,\n",
    "    description='Movie recommender system pipeline',\n",
    "    schedule_interval=timedelta(days=1),\n",
    "    catchup=False\n",
    ")\n",
    "\n",
    "# Define tasks\n",
    "t1 = PythonOperator(\n",
    "    task_id='fetch_tmdb_data',\n",
    "    python_callable=fetch_tmdb_data,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "t2 = PythonOperator(\n",
    "    task_id='process_movie_data',\n",
    "    python_callable=process_movie_data,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "t3 = PythonOperator(\n",
    "    task_id='build_feature_vectors',\n",
    "    python_callable=build_feature_vectors,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "t4 = PythonOperator(\n",
    "    task_id='generate_recommendations',\n",
    "    python_callable=generate_recommendations,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Set task dependencies\n",
    "t1 >> t2 >> t3 >> t4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
